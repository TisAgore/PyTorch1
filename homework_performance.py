# -*- coding: utf-8 -*-
"""homework_performance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xHSfmDZlQywczFMrJ8mjVR6apN01Dcp5
"""

!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

import torch as t
import time

"""## 3.1 Подготовка данных"""

# Создайте большие матрицы размеров:
# - 64 x 1024 x 1024
# - 128 x 512 x 512
# - 256 x 256 x 256
tensor64x1024x1024 = t.randint(11, (64, 1024, 1024), dtype=float)
tensor128x512x512 = t.randint(12, (128, 512, 512), dtype=float)
tensor256x256x256 = t.randint(13, (256, 256, 256), dtype=float)

"""## 3.2 Функция измерения времени"""

# Используйте torch.cuda.Event() для точного измерения на GPU
# Используйте time.time() для измерения на CPU
def execute_operations(*tensors):
    """
    Выполняет операцию ('matmul', 'add', 'mul', 'transpose', 'sum') на CPU или CUDA.
    Возвращает результат и время выполнения в секундах.

    Вход:
    Тензоры tuple[tensor]

    Выход:
    Время выполнения (секунды) (float)
    """
    operations = {
        'matmul': t.matmul,
        'add': t.add,
        'mul': t.mul,
        'transpose': t.transpose(0, 1),
        'sum': t.sum
    }
    operation_names = ['matmul', 'add', 'mul', 'transpose', 'sum']
    devices = ['cuda', 'cpu']

    tensors_cpu = [t.to(devices[1]) for t in tensors]
    elapsed_time_cuda = list()
    elapsed_time_cpu = list()

    if t.cuda.is_available():
      tensors_cuda = [t.to(devices[0]) for t in tensors]

      for operation_name in operation_names:
        start_event = t.cuda.Event(enable_timing=True)
        end_event = t.cuda.Event(enable_timing=True)
        t.cuda.synchronize()
        start_event.record()
        if operation_name == 'transpose':
          transp_tensors = list()
          for tensor in tensors_cuda:
            transp_tensors.append(operations[operation_name](tensor))
          result = transp_tensors
        else:
         result_cudo = operations[operation_name](*tensors_cuda)
        end_event.record()
        t.cuda.synchronize()
        elapsed_time = start_event.elapsed_time(end_event) / 1000.0
        elapsed_time_cuda.append(elapsed_time)
    else:
      elapsed_time_cuda = [0] * len(operation_names)

    for operation_name in operation_names:
      start_time = time.time()
      if operation_name == 'transpose':
        transp_tensors = list()
        for tensor in tensors_cpu:
          transp_tensors.append(operations[operation_name](tensor))
        result = transp_tensors
      else:
        result = operations[operation_name](*tensors_cpu)
      elapsed_time = time.time() - start_time
      elapsed_time_cpu.append(elapsed_time)

    return elapsed_time_cuda, elapsed_time_cpu

"""## 3.3 Сравнение операций"""

# Сравните время выполнения следующих операций на CPU и CUDA:
# - Матричное умножение (torch.matmul)
# - Поэлементное сложение
# - Поэлементное умножение
# - Транспонирование
# - Вычисление суммы всех элементов

# Для каждой операции:
# 1. Измерьте время на CPU
# 2. Измерьте время на GPU (если доступен)
cuda, cpu = execute_operations(tensor64x1024x1024, tensor64x1024x1024)

matmul_cuda = cuda[0]
add_cuda = cuda[1]
mul_cuda = cuda[2]
transpose_cuda = cuda[3]
sum_cuda = cuda[4]

matmul_cpu = cpu[0]
add_cpu = cpu[1]
mul_cpu = cpu[2]
transpose_cpu = cpu[3]
sum_cpu = cpu[4]

# 3. Вычислите ускорение (speedup)
# 4. Выведите результаты в табличном виде
print(f"Операция                        | CPU (мс) | GPU (мс) | Ускорение (раз)")
print(f"Матричное умножение             |   {matmul_cpu:.2f}   |   {matmul_cuda:.2f}   |     {matmul_cpu/matmul_cuda:.2f}")
print(f"Поэлементное сложение           |   {add_cpu:.2f}   |   {add_cuda:.2f}   |     {add_cpu/add_cuda:.2f}")
print(f"Поэлементное умножение          |   {mul_cpu:.2f}   |   {mul_cuda:.2f}   |     {mul_cpu/mul_cuda:.2f}")
print(f"Транспонирование                |   {transpose_cpu:.2f}   |   {transpose_cuda:.2f}   |     {transpose_cpu/transpose_cuda:.2f}")
print(f"Вычисление суммы всех элементов |   {sum_cpu:.2f}   |   {sum_cuda:.2f}   |     {sum_cpu/sum_cuda:.2f}")
