# -*- coding: utf-8 -*-
"""homework_autograd.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z0MucGEDXKYXnYBR7C7zeaZY4nn2QoPF
"""

!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

import torch as t
import math

"""## 2.1 Простые вычисления с градиентами"""

x = t.tensor(1.0, requires_grad=True)
y = t.tensor(2.0, requires_grad=True)
z = t.tensor(3.0, requires_grad=True)
# Вычислите функцию: f(x,y,z) = x^2 + y^2 + z^2 + 2*x*y*z
f = (x ** 2) + (y ** 2) + (z ** 2) + (2 * x * y * z)
# Найдите градиенты по всем переменным
f.backward()
print(f"Градиент по x: {x.grad}")
print(f"Градиент по y: {y.grad}")
print(f"Градиент по z: {z.grad}")

"""## 2.2 Градиент функции потерь"""

# Реализуйте функцию MSE (Mean Squared Error):
# MSE = (1/n) * Σ(y_pred - y_true)^2 где y_pred = w * x + b (линейная функция)
# Найдите градиенты по w и b
def mse_with_gradients(x, y_true, w, b):
    """
    Вычисляет MSE и градиенты по параметрам w и b

    Аргументы:
    x (torch.Tensor): Входные значения
    y_true (torch.Tensor): Истинные значения
    w (torch.Tensor): Весовой коэффициент (требует градиент)
    b (torch.Tensor): Смещение (требует градиент)

    Возвращает:
    tuple: (MSE, grad_w, grad_b)
    """
    y_pred = w * x + b
    mse = t.mean((y_pred - y_true)**2)

    mse.backward()
    grad_w = w.grad
    grad_b = b.grad

    return mse.item(), grad_w, grad_b

x = t.tensor([1.0, 2.0, 3.0])
y_true = t.tensor([2.0, 4.0, 6.0])
w = t.tensor(0.5, requires_grad=True)
b = t.tensor(0.1, requires_grad=True)

mse, grad_w, grad_b = mse_with_gradients(x, y_true, w, b)
print(f"MSE: {mse}")
print(f"Градиент по w: {grad_w}")
print(f"Градиент по b: {grad_b}")

"""## 2.3 Цепное правило"""

# Реализуйте составную функцию: f(x) = sin(x^2 + 1)
# Найдите градиент df/dx
x = 2.0
f = math.sin(x**2 + 1)
df_dx = math.cos(x**2 + 1) * 2 * x

print(f"Функция = {f:.4f}")     # -0.9589
print(f"Градиент = {df_dx:.4f}")  # 1.1346

# Проверьте результат с помощью torch.autograd.grad
x = t.tensor(2.0, requires_grad=True)
f = t.sin(x**2 + 1)
f.backward()
gradient = x.grad

print(f"PyTorch Функция = {f.item():.4f}")    # -0.9589
print(f"PyTorch Градиент = {gradient:.4f}")   # 1.1346